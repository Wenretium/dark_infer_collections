import torch

if __name__ == '__main__':
    weight = torch.load('pre_weights/EnlightenGAN/200_net_G_A.pth')
    key_dic = {
        'module.conv1_1.weight':     'encoder1.en1.0.weight',
        'module.conv1_1.bias':       'encoder1.en1.0.bias',
        'module.bn1_1.weight':       'encoder1.en1.2.weight',
        'module.bn1_1.bias':         'encoder1.en1.2.bias',
        'module.bn1_1.running_mean': 'encoder1.en1.2.running_mean',
        'module.bn1_1.running_var':  'encoder1.en1.2.running_var',
        'module.conv1_2.weight':     'encoder1.en2.0.weight',
        'module.conv1_2.bias':       'encoder1.en2.0.bias',
        'module.bn1_2.weight':       'encoder1.en2.2.weight',
        'module.bn1_2.bias':         'encoder1.en2.2.bias',
        'module.bn1_2.running_mean': 'encoder1.en2.2.running_mean',
        'module.bn1_2.running_var':  'encoder1.en2.2.running_var',

        'module.conv2_1.weight':     'encoder2.en1.0.weight',
        'module.conv2_1.bias':       'encoder2.en1.0.bias',
        'module.bn2_1.weight':       'encoder2.en1.2.weight',
        'module.bn2_1.bias':         'encoder2.en1.2.bias',
        'module.bn2_1.running_mean': 'encoder2.en1.2.running_mean',
        'module.bn2_1.running_var':  'encoder2.en1.2.running_var',
        'module.conv2_2.weight':     'encoder2.en2.0.weight',
        'module.conv2_2.bias':       'encoder2.en2.0.bias',
        'module.bn2_2.weight':       'encoder2.en2.2.weight',
        'module.bn2_2.bias':         'encoder2.en2.2.bias',
        'module.bn2_2.running_mean': 'encoder2.en2.2.running_mean',
        'module.bn2_2.running_var':  'encoder2.en2.2.running_var',

        'module.conv3_1.weight':     'encoder3.en1.0.weight',
        'module.conv3_1.bias':       'encoder3.en1.0.bias',
        'module.bn3_1.weight':       'encoder3.en1.2.weight',
        'module.bn3_1.bias':         'encoder3.en1.2.bias',
        'module.bn3_1.running_mean': 'encoder3.en1.2.running_mean',
        'module.bn3_1.running_var':  'encoder3.en1.2.running_var',
        'module.conv3_2.weight':     'encoder3.en2.0.weight',
        'module.conv3_2.bias':       'encoder3.en2.0.bias',
        'module.bn3_2.weight':       'encoder3.en2.2.weight',
        'module.bn3_2.bias':         'encoder3.en2.2.bias',
        'module.bn3_2.running_mean': 'encoder3.en2.2.running_mean',
        'module.bn3_2.running_var':  'encoder3.en2.2.running_var',

        'module.conv4_1.weight':     'encoder4.en1.0.weight',
        'module.conv4_1.bias':       'encoder4.en1.0.bias',
        'module.bn4_1.weight':       'encoder4.en1.2.weight',
        'module.bn4_1.bias':         'encoder4.en1.2.bias',
        'module.bn4_1.running_mean': 'encoder4.en1.2.running_mean',
        'module.bn4_1.running_var':  'encoder4.en1.2.running_var',
        'module.conv4_2.weight':     'encoder4.en2.0.weight',
        'module.conv4_2.bias':       'encoder4.en2.0.bias',
        'module.bn4_2.weight':       'encoder4.en2.2.weight',
        'module.bn4_2.bias':         'encoder4.en2.2.bias',
        'module.bn4_2.running_mean': 'encoder4.en2.2.running_mean',
        'module.bn4_2.running_var':  'encoder4.en2.2.running_var',

        'module.conv5_1.weight':     'encoder5.en1.0.weight',
        'module.conv5_1.bias':       'encoder5.en1.0.bias',
        'module.bn5_1.weight':       'encoder5.en1.2.weight',
        'module.bn5_1.bias':         'encoder5.en1.2.bias',
        'module.bn5_1.running_mean': 'encoder5.en1.2.running_mean',
        'module.bn5_1.running_var':  'encoder5.en1.2.running_var',
        'module.conv5_2.weight':     'encoder5.en2.0.weight',
        'module.conv5_2.bias':       'encoder5.en2.0.bias',
        'module.bn5_2.weight':       'encoder5.en2.2.weight',
        'module.bn5_2.bias':         'encoder5.en2.2.bias',
        'module.bn5_2.running_mean': 'encoder5.en2.2.running_mean',
        'module.bn5_2.running_var':  'encoder5.en2.2.running_var',

        'module.deconv5.weight':     'decoder6.deconv.weight',
        'module.deconv5.bias':       'decoder6.deconv.bias',
        'module.conv6_1.weight':     'decoder6.de.0.weight',
        'module.conv6_1.bias':       'decoder6.de.0.bias',
        'module.bn6_1.weight':       'decoder6.de.2.weight',
        'module.bn6_1.bias':         'decoder6.de.2.bias',
        'module.bn6_1.running_mean': 'decoder6.de.2.running_mean',
        'module.bn6_1.running_var':  'decoder6.de.2.running_var',
        'module.conv6_2.weight':     'decoder6.de.3.weight',
        'module.conv6_2.bias':       'decoder6.de.3.bias',
        'module.bn6_2.weight':       'decoder6.de.5.weight',
        'module.bn6_2.bias':         'decoder6.de.5.bias',
        'module.bn6_2.running_mean': 'decoder6.de.5.running_mean',
        'module.bn6_2.running_var':  'decoder6.de.5.running_var',

        'module.deconv6.weight':     'decoder7.deconv.weight',
        'module.deconv6.bias':       'decoder7.deconv.bias',
        'module.conv7_1.weight':     'decoder7.de.0.weight',
        'module.conv7_1.bias':       'decoder7.de.0.bias',
        'module.bn7_1.weight':       'decoder7.de.2.weight',
        'module.bn7_1.bias':         'decoder7.de.2.bias',
        'module.bn7_1.running_mean': 'decoder7.de.2.running_mean',
        'module.bn7_1.running_var':  'decoder7.de.2.running_var',
        'module.conv7_2.weight':     'decoder7.de.3.weight',
        'module.conv7_2.bias':       'decoder7.de.3.bias',
        'module.bn7_2.weight':       'decoder7.de.5.weight',
        'module.bn7_2.bias':         'decoder7.de.5.bias',
        'module.bn7_2.running_mean': 'decoder7.de.5.running_mean',
        'module.bn7_2.running_var':  'decoder7.de.5.running_var',

        'module.deconv7.weight':     'decoder8.deconv.weight',
        'module.deconv7.bias':       'decoder8.deconv.bias',
        'module.conv8_1.weight':     'decoder8.de.0.weight',
        'module.conv8_1.bias':       'decoder8.de.0.bias',
        'module.bn8_1.weight':       'decoder8.de.2.weight',
        'module.bn8_1.bias':         'decoder8.de.2.bias',
        'module.bn8_1.running_mean': 'decoder8.de.2.running_mean',
        'module.bn8_1.running_var':  'decoder8.de.2.running_var',
        'module.conv8_2.weight':     'decoder8.de.3.weight',
        'module.conv8_2.bias':       'decoder8.de.3.bias',
        'module.bn8_2.weight':       'decoder8.de.5.weight',
        'module.bn8_2.bias':         'decoder8.de.5.bias',
        'module.bn8_2.running_mean': 'decoder8.de.5.running_mean',
        'module.bn8_2.running_var':  'decoder8.de.5.running_var',

        'module.deconv8.weight':     'decoder9.deconv.weight',
        'module.deconv8.bias':       'decoder9.deconv.bias',
        'module.conv9_1.weight':     'decoder9.de.0.weight',
        'module.conv9_1.bias':       'decoder9.de.0.bias',
        'module.bn9_1.weight':       'decoder9.de.2.weight',
        'module.bn9_1.bias':         'decoder9.de.2.bias',
        'module.bn9_1.running_mean': 'decoder9.de.2.running_mean',
        'module.bn9_1.running_var':  'decoder9.de.2.running_var',
        'module.conv9_2.weight':     'decoder9.de.3.weight',
        'module.conv9_2.bias':       'decoder9.de.3.bias',

        'module.conv10.weight':      'decoder10.weight',
        'module.conv10.bias':        'decoder10.bias',
    }
    new_weight = {}
    for k, v in weight.items():
        if k in key_dic:
            new_weight[key_dic[k]] = v
    torch.save(new_weight, 'weights/EnlightenGAN/weight.pth')
